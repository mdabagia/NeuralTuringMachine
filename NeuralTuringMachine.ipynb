{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e840f1ee30>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1728, -0.4397,  0.1527]],\n",
      "\n",
      "        [[-0.1477, -0.1548,  0.2824]],\n",
      "\n",
      "        [[-0.1569, -0.1602,  0.2466]],\n",
      "\n",
      "        [[ 0.0118,  0.0166,  0.4544]],\n",
      "\n",
      "        [[-0.0297, -0.0051,  0.3407]]], grad_fn=<StackBackward>)\n",
      "(tensor([[[-0.0297, -0.0051,  0.3407]]], grad_fn=<StackBackward>), tensor([[[-0.0733, -0.0106,  0.7060]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)\n",
    "\n",
    "\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))\n",
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    \n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMController(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_inputs, num_outputs, num_layers):\n",
    "        super(LSTMController, self).__init__()\n",
    "        \n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_layers = num_layers\n",
    "                        \n",
    "        self.lstm = nn.LSTM(input_size=self.num_inputs, hidden_size=self.num_outputs, num_layers=self.num_layers, bias=True)\n",
    "        \n",
    "        self.h_bias = nn.Parameter(torch.randn(self.num_layers, 1, self.num_outputs) * 0.05)\n",
    "        self.c_bias = nn.Parameter(torch.randn(self.num_layers, 1, self.num_outputs) * 0.05)\n",
    "                \n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        for param in self.lstm.parameters():\n",
    "            if param.dim() == 1:\n",
    "                nn.init.constant_(param, 0)\n",
    "            else:\n",
    "                std = 5 / np.sqrt(self.num_inputs + self.num_outputs)\n",
    "                nn.init.uniform_(param, -std, std)\n",
    "    \n",
    "    def size(self):\n",
    "        return (self.num_inputs(), self.num_outputs())\n",
    "    \n",
    "    def create_new_state(self, batch_size):\n",
    "        lstm_h = self.h_bias.clone().repeat(1, batch_size, 1)\n",
    "        lstm_c = self.c_bias.clone().repeat(1, batch_size, 1)\n",
    "        return lstm_h, lstm_c\n",
    "    \n",
    "    def forward(self, inputs, prev_state):\n",
    "        outputs, new_state = self.lstm(inputs.unsqueeze(0), prev_state)\n",
    "        return outputs.squeeze(0), new_state\n",
    "        \n",
    "    \n",
    "def convolve_circularly(w, s):\n",
    "        t = torch.cat([w[-1:], w, w[:1]])\n",
    "        return F.conv1d(t.view(1, 1, -1), s.view(1, 1, -1)).view(-1)\n",
    "    \n",
    "class MemoryBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_cells, cell_size):\n",
    "        super(MemoryBlock, self).__init__()\n",
    "        self.num_cells = num_cells\n",
    "        self.cell_size = cell_size\n",
    "        self.register_buffer('mem_bias', torch.Tensor(num_cells, cell_size))\n",
    "        nn.init.constant_(self.mem_bias, 1e-6)\n",
    "               \n",
    "    def size(self):\n",
    "        return self.num_cells, self.cell_size\n",
    "    \n",
    "    def reset(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.memory = self.mem_bias.clone().repeat(batch_size, 1, 1)\n",
    "        \n",
    "    def read(self, read_weight):\n",
    "        return torch.matmul(read_weight.unsqueeze(1), self.memory).squeeze(1)\n",
    "    \n",
    "    def write(self, write_vec, erase_weight, add_vec):\n",
    "        self.memory = self.memory * (1 - torch.matmul(write_vec.unsqueeze(-1), erase_weight.unsqueeze(1))) + torch.matmul(write_vec.unsqueeze(-1), add_vec.unsqueeze(1))\n",
    "        \n",
    "    def address(self, key, key_weight, gating_factor, shift_weight, sharpening_factor, prev_weight):\n",
    "        content_weight = self._content_addressing(key, key_weight)\n",
    "        interp_weight = self._interpolate(prev_weight, content_weight, gating_factor)\n",
    "        rotated_weight = self._shift(interp_weight, shift_weight)\n",
    "        final_weight = self._sharpen(rotated_weight, sharpening_factor)\n",
    "        return final_weight\n",
    "        \n",
    "        \n",
    "    def _content_addressing(self, key, key_weight):\n",
    "        key = key.view(self.batch_size, 1, -1)\n",
    "        return F.softmax(key_weight * F.cosine_similarity(self.memory + 1e-16, key + 1e-16, dim=-1), dim=1)\n",
    "    \n",
    "    def _interpolate(self, prev_weight, content_weight, gating_factor):\n",
    "        return gating_factor * content_weight + (1 - gating_factor) * prev_weight\n",
    "    \n",
    "    def _shift(self, interp_weight, shift_weight):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        result = torch.zeros(interp_weight.size(), device=device)\n",
    "        for batch_num in range(self.batch_size):\n",
    "            result[batch_num] = convolve_circularly(interp_weight[batch_num], shift_weight[batch_num])\n",
    "        return result\n",
    "    \n",
    "    def _sharpen(self, rotated_weight, sharpening_factor):\n",
    "        sharpened_weight = rotated_weight ** sharpening_factor\n",
    "        return torch.div(rotated_weight, torch.sum(sharpened_weight, dim=1).view(-1, 1) + 1e-16)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cols(mat, lengths):\n",
    "    cum_lengths = np.cumsum([0] + lengths)\n",
    "    results = []\n",
    "    for s, e in zip(cum_lengths[:-1], cum_lengths[1:]):\n",
    "        results += [mat[:, s:e]]\n",
    "    return results\n",
    "\n",
    "class GenericHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, memory, controller_size):\n",
    "        super(GenericHead, self).__init__()\n",
    "        self.memory = memory\n",
    "        self.num_cells, self.cell_size = self.memory.size()\n",
    "        self.controller_size = controller_size\n",
    "                \n",
    "    def _address_memory(self, key, key_weight, gating_factor, shift_weight, sharpening_factor, prev_weight):\n",
    "        key = key.clone()\n",
    "        key_weight = F.softplus(key_weight)\n",
    "        gating_factor = F.sigmoid(gating_factor)\n",
    "        shift_weight = F.softmax(shift_weight, dim=0)\n",
    "        sharpening_factor = 1 + F.softplus(sharpening_factor)\n",
    "        \n",
    "        return self.memory.address(key, key_weight, gating_factor, shift_weight, sharpening_factor, prev_weight)\n",
    "    \n",
    "    \n",
    "class ReadHead(GenericHead):\n",
    "        \n",
    "    def __init__(self, memory, controller_size):\n",
    "        super(ReadHead, self).__init__(memory, controller_size)\n",
    "\n",
    "        self.read_lengths = [self.cell_size, 1, 1, 3, 1]\n",
    "        self.read_input = nn.Linear(controller_size, sum(self.read_lengths))\n",
    "        self.reset()\n",
    "        \n",
    "    def create_new_state(self, batch_size):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return torch.zeros(batch_size, self.num_cells, device=device)\n",
    "\n",
    "    def reset(self):\n",
    "        nn.init.xavier_uniform_(self.read_input.weight, gain=1.4)\n",
    "        nn.init.normal_(self.read_input.bias, std=0.01)\n",
    "\n",
    "    def forward(self, embeddings, prev_weight):\n",
    "        read_params = self.read_input(embeddings)\n",
    "\n",
    "        key, key_weight, gating_factor, shift_weight, sharpening_factor = split_cols(read_params, self.read_lengths)\n",
    "\n",
    "        address_weight = self._address_memory(key, key_weight, gating_factor, shift_weight, sharpening_factor, prev_weight)\n",
    "        return self.memory.read(address_weight), address_weight\n",
    "\n",
    "class WriteHead(GenericHead):\n",
    "\n",
    "    def __init__(self, memory, controller_size):\n",
    "        super(WriteHead, self).__init__(memory, controller_size)\n",
    "\n",
    "        self.write_lengths = [self.cell_size, 1, 1, 3, 1, self.cell_size, self.cell_size]\n",
    "        self.write_input = nn.Linear(controller_size, sum(self.write_lengths))\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        nn.init.xavier_uniform_(self.write_input.weight, gain=1.4)\n",
    "        nn.init.normal_(self.write_input.bias, std=0.01)\n",
    "        \n",
    "    def create_new_state(self, batch_size):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        return torch.zeros(batch_size, self.num_cells, device=device)\n",
    "\n",
    "    def forward(self, embeddings, prev_weight):\n",
    "        write_params = self.write_input(embeddings)\n",
    "\n",
    "        key, key_weight, gating_factor, shift_weight, sharpening_factor, error_weight, add_vector = split_cols(write_params, self.write_lengths)\n",
    "\n",
    "        error_weight = F.sigmoid(error_weight)\n",
    "\n",
    "        address_weight = self._address_memory(key, key_weight, gating_factor, shift_weight, sharpening_factor, prev_weight)\n",
    "        self.memory.write(address_weight, error_weight, add_vector)\n",
    "        \n",
    "        return address_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralTuringMachine(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs, controller_size, num_cells, cell_size, num_read_heads, num_write_heads):\n",
    "        super(NeuralTuringMachine, self).__init__()\n",
    "        \n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_outputs = num_outputs\n",
    "        self.controller_size = controller_size\n",
    "        self.num_cells = num_cells\n",
    "        self.cell_size = cell_size\n",
    "        self.num_read_heads = num_read_heads\n",
    "        self.num_write_heads = num_write_heads\n",
    "        \n",
    "        self.memory = MemoryBlock(num_cells, cell_size)\n",
    "        self.controller = LSTMController(num_inputs + cell_size * num_read_heads, controller_size[0], controller_size[1])\n",
    "        self.read_heads = nn.ModuleList([])\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.init_read = []\n",
    "        for i in range(num_read_heads):\n",
    "            self.init_read += [torch.randn(1, cell_size, device=device) * 0.01]\n",
    "            self.register_buffer(\"read_bias{}\".format(i + 1), self.init_read[i].data)            \n",
    "            self.read_heads += [ReadHead(self.memory, self.controller_size[0])]\n",
    "                    \n",
    "        self.write_heads = nn.ModuleList([])\n",
    "        for i in range(num_write_heads):\n",
    "            self.write_heads += [WriteHead(self.memory, self.controller_size[0])]\n",
    "        \n",
    "        self.output_layer = nn.Linear(self.controller_size[0] + num_read_heads * self.cell_size, self.num_outputs)\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        nn.init.xavier_uniform_(self.output_layer.weight, gain=1)\n",
    "        nn.init.normal_(self.output_layer.bias, std=0.01)\n",
    "        \n",
    "    def create_new_state(self, batch_size):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        init_read = [r.clone().repeat(batch_size, 1) for r in self.init_read]\n",
    "        controller_state = self.controller.create_new_state(batch_size)\n",
    "        head_states = [head.create_new_state(batch_size) for head in self.read_heads] + [head.create_new_state(batch_size) for head in self.write_heads]\n",
    "            \n",
    "        return init_read, controller_state, head_states\n",
    "    \n",
    "    def init_sequence(self, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.memory.reset(batch_size)\n",
    "        self.prev_state = self.create_new_state(batch_size)\n",
    "\n",
    "    def forward(self, inputs=None):\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        if inputs is None:\n",
    "            inputs = torch.zeros(self.batch_size, self.num_inputs, device=device)\n",
    "            \n",
    "        prev_reads, prev_controller_state, prev_head_states = self.prev_state\n",
    "        controller_output, controller_state = self.controller(torch.cat([inputs] + prev_reads, dim=1), prev_controller_state)\n",
    "        \n",
    "        reads = []\n",
    "        head_states = []\n",
    "        \n",
    "        for read_head, prev_head_state in zip(self.read_heads, prev_head_states):\n",
    "            r, head_state = read_head(controller_output, prev_head_state)\n",
    "            reads += [r]\n",
    "            head_states += [head_state]\n",
    "            \n",
    "        for write_head, prev_head_state in zip(self.write_heads, prev_head_states):\n",
    "            head_state = write_head(controller_output, prev_head_state)\n",
    "            head_states += [head_state]\n",
    "        \n",
    "        outputs = torch.sigmoid(self.output_layer(torch.cat([controller_output] + reads, dim=1)))\n",
    "        self.prev_state = (reads, controller_state, head_states)\n",
    "        \n",
    "        return outputs, self.prev_state\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_copy_batch(batch_size, seq_len, num_bits):            \n",
    "        seq = torch.from_numpy(np.random.binomial(1, 0.5, (seq_len, batch_size, num_bits)))\n",
    "        input_seq = torch.zeros(seq_len + 1, batch_size, num_bits + 1)\n",
    "        input_seq[:seq_len, :, :num_bits] = seq\n",
    "        input_seq[seq_len, :, num_bits] = 1.0\n",
    "        target_seq = seq.clone()\n",
    "\n",
    "        return input_seq.float(), target_seq.float()\n",
    "        \n",
    "def clip_grads(ntm):\n",
    "    parameters = list(filter(lambda p: p.grad is not None, ntm.parameters()))\n",
    "    for param in parameters:\n",
    "        param.grad.data.clamp_(-10, 10)\n",
    "\n",
    "def train_batch(ntm, criterion, optimizer, input_batch, target_batch):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimizer.zero_grad()\n",
    "    input_seq_len = input_batch.size(0)\n",
    "    output_seq_len, batch_size, _ = target_batch.size()\n",
    "    \n",
    "    ntm.init_sequence(batch_size)\n",
    "    \n",
    "    for i in range(input_seq_len):\n",
    "        ntm(input_batch[i])\n",
    "        \n",
    "    output_batch = torch.zeros(target_batch.size(), device=device)\n",
    "    for i in range(output_seq_len):\n",
    "        output_batch[i], _ = ntm()\n",
    "        \n",
    "    batch_loss = criterion(output_batch, target_batch)\n",
    "    batch_loss.backward()\n",
    "    clip_grads(ntm)\n",
    "    optimizer.step()\n",
    "    \n",
    "    output_batch_bin = output_batch.clone().data.round_()    \n",
    "    \n",
    "    batch_cost = torch.sum(torch.abs(output_batch_bin - target_batch.data))\n",
    "    \n",
    "    return batch_loss.item(), batch_cost.item() / batch_size\n",
    "\n",
    "def evaluate(ntm, criterion, input_batch, target_batch):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_seq_len = input_batch.size(0)\n",
    "    output_seq_len, batch_size, _ = target_batch.size()\n",
    "    \n",
    "    ntm.init_sequence(batch_size)\n",
    "    \n",
    "    states = []\n",
    "    for i in range(input_seq_len):\n",
    "        _, state = ntm(input_batch[i])\n",
    "        states += [state]\n",
    "        \n",
    "    output_batch = torch.zeros(target_batch.size(), device=device)\n",
    "    for i in range(output_seq_len):\n",
    "        output_batch[i], state = ntm()\n",
    "        states += [state]\n",
    "        \n",
    "    batch_loss = criterion(output_batch, target_batch)\n",
    "    \n",
    "    output_batch_bin = output_batch.clone().data.round_()    \n",
    "    \n",
    "    batch_cost = torch.sum(torch.abs(output_batch_bin - target_batch.data))\n",
    "    \n",
    "    result = {\n",
    "        'loss': batch_loss.data.item(),\n",
    "        'cost': batch_cost / batch_size,\n",
    "        'output_batch': output_batch,\n",
    "        'output_batch_bin': output_batch_bin,\n",
    "        'states': states\n",
    "    }\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: 0.28 seconds\n",
      "Epoch #2: 2.3e+03 seconds\n",
      "Epoch #3: 1.6e+04 seconds\n",
      "Epoch #4: 1.8e+04 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-256-49ac25a5b77c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_copy_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_len_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len_max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_bits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0minput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mlosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbatch_num\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5000\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[0mtoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-244-20173bbcc1f5>\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(ntm, criterion, optimizer, input_batch, target_batch)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mbatch_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mclip_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \"\"\"\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "controller_width = 100\n",
    "controller_depth = 1\n",
    "num_read_heads = 1\n",
    "num_write_heads = 1\n",
    "num_bits = 8\n",
    "seq_len_min = 1\n",
    "seq_len_max = 20\n",
    "num_cells = 128\n",
    "cell_size = 8\n",
    "num_batches = 50000\n",
    "batch_size = 1\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "ntm = NeuralTuringMachine(num_bits + 1, num_bits, (controller_width, controller_depth), num_cells, cell_size, num_read_heads, num_write_heads)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.RMSprop(ntm.parameters(), momentum=0.9, alpha=0.95, lr=1e-4)\n",
    "ntm.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "losses = np.zeros(num_batches, dtype=float)\n",
    "costs = np.zeros(num_batches, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: 0.59 seconds\n",
      "Epoch #8: 2.3e+03 seconds\n",
      "Epoch #9: 4.6e+03 seconds\n",
      "Epoch #10: 1.4e+04 seconds\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "\n",
    "for batch_num in range(30000, num_batches):\n",
    "    batch = get_copy_batch(batch_size, np.random.randint(seq_len_min, seq_len_max), num_bits)\n",
    "    input_batch, target_batch = batch[0].to(device), batch[1].to(device)\n",
    "    losses[batch_num], costs[batch_num] = train_batch(ntm, criterion, optimizer, input_batch, target_batch)\n",
    "    if batch_num % 5000 == 0:\n",
    "        toc = time.time()\n",
    "        print(\"Epoch #{}: {:.2} seconds\".format(batch_num // 5000 + 1, toc - tic))\n",
    "    \n",
    "toc = time.time()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Time Elapsed: 15794.602104663849 Seconds')"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XecVtWdx/HPT9HYYkHQqKhYMIquLcTEmLhuNMWy0WR1Y9loEhPiborG3SRo1KjRBDXG3rB3sTdEQYqISBl6hwEpQ5uhDMMAw7Szf9zzwJ1nnl5nrt/36/W85j7ntnOeuc/vOffcc8815xwiItL5bVfuDIiISGEooIuIRIQCuohIRCigi4hEhAK6iEhEKKCLiETE5z6gm9m1ZvZYB8jHU2Z2S7nzEWNmPc3MmVmXcudFpBTMbKSZ/aLc+chH5AO6mdWHXq1mtjn0/hLn3N+cc0X/J4YCZH3c68fF3ncpmNlvzKzCzLaY2VNx8xKV/frQ/Jlx85rN7J3Q/H83sxl+3hgz650kD8PT/QiZ2S5m9qCZrTaz9WY2KjTPzOw2M1vjX7ebmfl5R5jZW2ZWY2ZrzewDM/tyaN1jfNpqM2t3c4eZdTWzN8xso5ktNrOLk+TvSV+Gw+PSLzSz2X79BWb2rQzLdJWZLTSzOjNbbmZ3hT8fMzvezD7261WZ2Q1J8vUXn68zQmkH+M9krV/3imSfu1/+WjP7zP8fq8xsYKrlJXuRr30553aLTZvZIuAXzrkPy5cj9nTONZdx/8WyHLgF+B6wc5JlEpbdOXd0bNoH0AXAK/59L+B54CxgLPAH4G0zOzK8LTO7hMyO5wF+uaOAtcDxoXl9gfOA4wAHDAUWAg8DewJvAz8DNgA3AG8BR/p1m4CXgQeBNxPs9wGgEdjX73OQmU11zs0MleGbwGHxK5rZd4DbgB8D44H9sijTO8BTzrlaM+sKvAr8Dvinn/8C8AZwGtATGG1mU5xzb4f2fxhwPrAibr/PAVP9vN7ACDOb65wbkaAMlwE/Ac5wzi0wsy8BP2j/MUlenHOfmxewiOCACqfdCDznp3sSfJF/BiwF1gFXAF8FpgG1wP1x6/8cmO2X/QA4OMm+Y9vukmT+U8Atfnov4F2gxm/3XaBHaNmRwN8JvtzrCQJLVz9vJ4Iv2hqf3wnAvn7eHsDjBF/MZQQBeHs/b3vgH8BqgiD261T5TfEZ30IQQDIue9yy/wrUA7v6978BBoXmbwdsBk4Ppe0BzAO+nuYz/jJQB+yeZP4YoG/o/eXA2CTLdvX72jsu/fDga9UmbVeCYH5EKO1ZoH/ofRdgMnCs3+7hcfm6PJcyxS27N/Ah8GAobRPQO/T+FeCauPUGE/ygLsJ/f4DdfD67h5YbADybZN/3A3enyFvSY9PP/yXB92wDMAs40acfRfB9qAVmAj+I+049AAzy640DDgvN/w4wh+A7dD/wEUGFL/Z//MjPWw0MzOZ7UK5X5JtccvQ1oBdBjehu4M/AGcDRwH+a2b8CmNl5wLXAj4DuwMfAiwXY/3bAk8DBwEEEAez+uGUuJfgx2R9oBu716ZcRfDkOJPgCX+HXB3jaL3s4cALwXSDW3PRL4Byf3oeg1rWVmfUzs3fzLNdif6r9pJl1S7LMZcCrzrmNsV37F3Hvjwml/Q14CFiZZv9fAxYDN/nmielm9h+h+UcT1Dhjpvq0RE4FVjrn1qTZJ8ARQItzbl6Kbf8eGOWcmxZe0cy2J/h/dDezSv/53W9msbOgdGXCzC42szqCwHQc8Eho9t3ApWa2g29COpkg6MfWvQBodM69F1cmi/sbmz6GxMb6/fzBzPr4coUlPTZ9Hm4kOOZ3J6jZrzGzHQjOQIYA+wC/BZ4PN4UBFwE3EVSSKoFb/Ta7Aa8B1wHdCM4KTwmt91e/3b2AHsB9ScrVsZT7F6WULzKvoR8Qmr8G+HHo/WvAVX56MKGaE0Eg3kSCWnpo27Vxr6NCtYlbkuT7eGBd6P1I2tbuehPUALcnCPJjgGPjtrEvsAXYOZR2ETDCTw8HrgjN+y6Fq6HvRhCUuvh8vAp8kGDdXQhqm6eF0o4ENhI0CewIXA+04muRfrtT/LZ7psozwY+v8//zHdl2NhD7H7QAR4aW7+WXt7jt9CCoRV6UYB+JaujfIgj+4bRfAiP99IEEwWYP/35rDZ3gB9sBFQRNLd2AT4BbMylT3D57EQSqL4XSvuH33ey3c1Pc/20+cEii7w8wmiDQ7QScSNDcMzfFsXEJwY/FRoLvVb8Mj80PgCsTbO9bBD/i24XSXgRuDH2nHgvNOwuY46cvJXT2RfBjVMW2GvozBGccPZKVpyO+VENPbFVoenOC97F2+YOBe8ys1sxqCQ5oAw5Ise1uzrk9Q6/Z8Qv4i1yP+ItndcAoYM+4Ws3S0PRiYAeCL/uzBF+Al/xFsNt9TeZgv8yKUH4fIajZQBA44rdZEM65eudchXOu2Tm3iqAZ5btmtnvcoj8i+Aw/Cq07h6DWfj/B6Xg3glPuKjPbjqDN+kqX2XWJzQRt3bc45xqdcx8BIwh+vCAIhOE87Q7UO/8NBzCz7gQ1twedc5mejcVvN7btDX76buBm59z6JHkGuM85t8I5t5qg/fusDMu0lXNuPkGzxIO+LF2B94GbCYLygcD3zOx//Co3ETShfJakXJcAhxAcNw8RXOuoSrIszrnnnXNnEFyPuAK42cy+R/pj80CCGnS8/YGlzrnWUNpi2n7/wmdtm9j23W1zvPv/cfj4/yPBd3m8BRftf56sXB2JAnp+lgK/igvQOzvnxuS53f8laBv9mnNud4LTe2h7entgaPoggi/1audck3PuJudcb4La1zkEtZGlBLWg8A/K7m7bBckVCbZZLLEAaXHplwHPhAMogHPuVefcMc65vYG/EASACQRBsQ8w0MxW+jQIgv23aG9agrSwmQRNEjHH+bQgs2Z7EQTzt51zt6bZVtg8oIu/wJto26cDd5jZSl8OgE/N7GLn3DqCINnmMwlJV6Z4Xdh24fVQgqagZ/yPbRXwEtt+LE4HfhfK14HAy2b2JwDn3GLn3DnOue7Oua8RNPGNT5cBf4y+4vN+DOmPzaUkuFhMcCH+QP/DHnMQwdlTOm2Od38xfut759xK59wvnXP7A78CHozvedQhlfsUoZQvMm9y6RKaX0XbJoDngOv89A+BGcDR/v0ewAVJ9t1u23Hzn2LbRdHbCZpzdiK4+PZGeF2CJpcqgqaWXQguZL3g5/0b8C8EzS9dCdpqf+rnvQXcQxAItyP4kvyrn/ffBDXfHgTthsNS5TdB/rv4/P6d4Cxhp1B+v0bwA7UdwZd+IP50OrR+D4LT/sMSbPsrvjzd/bqxshrwpdDrqz7PBwA7JtjODgTNC9f7/J5CUEs+0s+/guDC2wEENbiZ+GYo/5mNJ+6ieGjb5svc2+dhJ+ALofkvETQH7Or3uz503OwTVw5HcIF3Zz//ZoIfq338/+Zj4K8ZlukXwD5+urcv0z9DZaoFLvb/my8Bn7KtOWfvuHwtBS4AdvPzjwK+SNDU818EbfTdk3w+PwXO9stvB5xJcHbxzQyOzQv8vr/iP+fDCX7UdySouffzn8NpcWV/ilAzpp9f5ae7+WV/5D+3KwmOv1+E9tnDTx/t83pIuWNY2u9huTNQ0sIWOKD79z8BphO0/S4Fnkiy79i26+NeV8cffATBZKSfP4+ghhAf0GO9XOoILgx18/MuAuYStFOuIrhYGltvD4JT4yqCgDIZuNDP6wLcRdC2+RlxvVwI2moHp/hsb/TLh183hvL0mc/TCoL2yS/FrX8N8HGSbY/2X761BKfiu6b5jMP/v5nAJaH3RxMErY0EP2A/DM0zgh/Ttf51O779nODswfn1wv+/g+L2HX4tCm27K0F3xo3AEuDiFJ+lo20vlx0ImklqCZoQ7gV2yrBMT/rjYCPB8X9H3LrfJvixWO+3/SiwSybfH+Aqgp5YG/3/qE+KMv2IoO1/HcExOx1f0Uh3bPr5VxAc1/UElagTQmWP9UaJL/tTJAno/v33Cb5fiXq53E5Q068n+NHom6xsHekVO1ilEzGzkQQ/QmW/w1VEOg61oYuIRIQCuohIRKjJRUQkIlRDFxGJiJIOztWtWzfXs2fPUu5SRKTTmzhx4mrnXPd0y5U0oPfs2ZOKiopS7lJEpNMzs4zu3FaTi4hIRCigi4hEhAK6iEhEKKCLiESEArqISEQooIuIRIQCuohIREQmoM9Ytp6pS2vLnQ0RkbIp6Y1FxXTOfaMBWNT/7DLnRESkPDpFDb2hqYW6hqZyZ0NEpEPrFAH93Ps/4dgbh5Q7GyIiHVqnCOhzV21Iv5CIyOdcpwjoIiKSngK6iEhEdKqA3tDUUu4siIh0WJ0qoN83fH65syAi0mF1qoC+qbGF6g0NzFi2ntX1W8qdHRGRDqXT3Vh00q3Dtk7rJiIRkW06VQ1dRESSyyigm9nvzWymmc0wsxfNbCczO8TMxpnZfDMbaGY7FjuzT36yqM37I/48uNi7FBHpNNIGdDM7APgd0Mc5dwywPXAhcBtwl3OuF7AOuLyYGU2ksaW11LsUEemwMm1y6QLsbGZdgF2AFcC3gVf9/KeB8wqfvfQW1NRz2/tz0i43Y9l67humXjIiEl1pL4o655aZ2T+AJcBmYAgwEah1zjX7xaqAAxKtb2Z9gb4ABx10UCHy3Malj49nWe3mtMvFRmP87em9Cp4HEZGOIJMml72Ac4FDgP2BXYEzEyzqEq3vnBvgnOvjnOvTvXv3fPKaUCbB/NMFawq+XxGRjiaTJpczgM+cczXOuSbgdeAbwJ6+CQagB7C8SHnMS82GLVz06NhyZ0NEpOgyCehLgK+b2S5mZsDpwCxgBHC+X+Yy4K3iZDE/2QwX0NLqaG1NeKIhItLhpQ3ozrlxBBc/JwHT/ToDgD8BV5tZJbA38HgR81kSvf78Ht+9e1S5syEikpOM7hR1zv0F+Etc8kLgpILnqIxaHVRW15c7GyIiOYncnaKXPDaWUfNqks5/YEQlv3h6AuMW5n6hdMjMlfx+4BQAZi2v45LHxmokSBEpu8gF9E8q1/DTJ8cnnX/HB3P5cHY1v35hcs776PvsRN6YvAyAG96awSeVa5i+bH3O2xMRKYTIBfRcvTG5Kut1Zi5XEBeRjkMBHZi3agO/Hzg16/XOvnd0EXIjIpKbTjd8bqZaWx2rN6YfM31zYwvVdRpbXUQ6v8gG9Ls+nMd9wyt59YqTUy532j9GsEoBXUQiILJNLsPnVAOkfbKRgrmIREUkA3qrg+oNQaC+4rlJSZd76pPPSpUlKaLHPl7Imfd8XO5siJRdZJtcajakrnmbwY3vzCpRbqSYbhk0u9xZEOkQIllDz0S6gF/X0MSxN37AiDnVvDxhaYlyJSKSu8jW0PP1q2cmUtfQzM+emgDAf371wDLnSEQktc9tDT2duoamdmkNTS3MXbkh4fKugIM0Vtc1MHJuNVuaNZyAiGRONfQMra7fws3vzOLtqW2HfTcr/L5O+tswAC786oH0/49jC78DEYkk1dAzVN/QzPjP1pZ0n5OWrCvp/kSkc1NAT2JBTdthdD9ZsLrkeZi3SkP5ikjmFNCTaGhqbfP+jUnLypQTEZHMKKAnMH9V+wufFYvXsbKuoV36hEWlaRZ5YEQlFYvyb/JxzvH3wbOZl6CMUnqvTazinakd8nG80gkpoCdw6RPJx1Mvlzs+mMv5D3+a93ZW1zfyyEcLueSxcQXIleTrf1+Zym9fzH1sfpEwBfQEVqxvXxNPZ/T8GjZuaW6T9rFPGzWvhk2Nwbzb3p/DKl/Tn7BoLWvqtzBreR1L1mxKuu2pS2uzzk8yjqB/ZSG7Wco2q+u3FORMSiQX6rZYIPcOr6Sypp4HL/kKAFXrNvGTx8dz5Je+yJyVGzj3+P257Bs9eWjkAh4auYBF/c/mgoc/5dDuu7KwZiMAi/qfnXDb5z7wScnKIfn50YNjWLJ2U9L/pUgxqYZeQHNXbqCxuZWGphZqNwU3Js3xNyItrNnIuo2N7daJBXOAllZHc0tru2XitbY6mpIsl2peMs0trRnttxhyyW+Mc47G5tzWLdZNW0vWBmdauZap0PL5fKXzUUAvoAU1GzniusEcef37nHNf6qcZTUnQjHL2vR9z+J8Hp91P32cn0ivJcv/3ytSk85I54eahW29mKrWrBk7JOr8xD45cwBHXZb/uu9OW8+Xr3i/qheFcy1Rolzw2rsPkRYpPAb1MJi1u3ztmTpJhBeJ9OHtV0nmvT86+e+WGLc2sTXD2UArxd95m4/VJ2T8HFmDorODzm7W8Lud9dxafLlxT7ixICSmgl8nN7+Y/dO9h176Xc9PB6votuBRXRt+YXMXVA6e0Sfvdi5OTdrG7euCUnB60XU6xC8T5aGhq4YKHxzC9KvUDw+8bNp9/Dp2XdP7f35vNgFEL8s5PPp75dBF/eWtG0bY/ev5qLn1iPK2tpbki/8bkKq5+eUr6BSNEAb0Ta2l1bdrgsxV/81TY7wdObVfbf3vq8qRd7F6fvCynB23nI9ewEBt+pxA9fWatqGPConVcnyYQ3jl0HvcOm590/iOjFvK39+bkn6E83PDWTJ7+dHHRtt/32QpGzathc1NpBp37/cCpvP45uyFQAb1EWp3jubHZf1lS1aJzEtpcphcUq+saMm4aeXbsYlqKUAMbNG0FK9ZvTrvcyxOWJhwpM2xGjk0tI+ZUtxsSopSaWlp5LsfPN5dacWNzsL9S1agTeX1SVcLOBJKYAnqJzFxex4i5NVmvN7mAfdDj3Ts8eY0x7JLHxvG7DG9+uf7NGbwwrrC1POccv35hEuc/lPrGqqlLa/nja9O45rXpKZerrK73280uHz97agKn3/lRdisV0IBRC7nuzRkMzOGBK7lcq3hgRCXXvTkjp+syhbB4zUaufnkqv3kx+WMkpS0F9A5uc2Pb09OFcTXEbC9mLqvdVstdtyn9upsam7O+0aquoTn9QlmIBd5w3huaWtqVPXYqX5PmweBbt0vwY7G8Nn3Nf1kGyxSLc45ltZtZvzk489iQ4AxkQU19ymNhdf0W1oQ+lw0NTVu3l0ylP9bq/f6aW1qpWreJ6g3Z33gHsKkxu6aW2BmkHuSeOQX0TubbcTXEbG7h/6RyNT98cEybtHQXVb/zz1GZZ85L1+SRrclL2/cIOv/hMVv7+ufj+XFL+Eb/4UyrSn4mNG7hGk7pPzzvfeXqtUnLOKX/cCakuAP19Ds/4sS/Dk06/5ZBs/nKLR9ufX/CzUM57qYhKfc7aNqKNu9vfncW37xtBCfdOizr+xZWJRgHSQpPAf1zJFE3vaaW1O0OudRMN20p7EWv+QmGEZ6xLP8uh865rUEy1cXluWUeyGyi7+Ka6HPIVXMO7eLDZldvnW7Jsr0q/AzfYjwURgIK6B1cJjXwI68fzLDZq7g/1CY+ev5qevYb1KZmlOiLlMlF1/q4MWpW1TXQs98gplXVsm5jI4df+17abWTihXFL+OqtH7ZLzzR0XDhgbML0hqYWevYbxPkPtT07CW83vnvbt+8cySMfpe5G2LPfIH7kz3imLK3llgJ0RU0l/v8Qzkc+bnpnJhc/mvizA1izsZFDrxlUsGYno/2B2NrqOPGvQ3m5Iv8HsseOz0KoWreJnv0GZX3Pwr/fNzplN9ViUUCPgIamVv4xZB7/GLLtAPrTa9MA+Hj+tgdzWIGqRqPmBRd3nx6zmClVte1qe7n27772jeltanJbt5dnJ4tq3wZbkeBmrpj4CuvCmo38fXB23QgfG/1Z1nnrCJ78ZBFjFiS/AWnCorXtPp9Ca2xpZe3GRq57M/9+8LHjsxBiZyUvTViS1XrTl61P2U21WBTQI2LuysQ1iDuHzN3aTh4fzofOWkX/UNCauXw9AzM4cKsTBN2wwdNX8vbU5TwwojLjbpfXh77IN78zi579ttUIwz8QD3+0IG1Ncfxna/njq0Gf+OfGLk5+i38eQSrRmPnF0zajTS2t3DlkLmMXruHViW1v5nr200Xc8+F81tRvYficxHcU5zr+TUfz0vgled/t29zSyj+HzE14oTn2OXcmGm0xIpLVoFasb+DpMYvoe+ph7ZpcNjQ08/y4bQH87HuD8Wd+/NWDUu7rjg9SH+RrNjZu7eZ4aq/u/EuPPdLkPui/HvPEJ0FN9/KnJvD+Vae2qaH3HzyHNzPoRvdyRRW3n39c2hpfrucs37/n4xzXzN9LE5ZStW4z9w2vbDfv+rdmAkENMdkQEeFmjUz69ndU/V4PuqfmM7Llu9NWcO/wStZuauSW8/6lzbxXKqoK3mOr2BTQPwcmLl7HiLnVGTddFHLQqpnL12cU0BPZ2NjMlKW1tMZlvFB3GiZqGsokwDU0tWR0c0/1hgYGTVvBGUft225ea6tj2rLUwwUkU7UuszwmSw+Pr5/omKhat4kdt0998j5/VT3HHJD4/1rX0ER1XQOH7/PFhPPNYHrVeuasrKO51fGNw/ZmdX37LpdrQt0w67c0s7x2M0fsm3ibAEvXbmJVXUO77pvzVm1g/z13ZrcvtA93jb63TqK7prMZpXLjlmaq1m2moakl6edSCgroERXujvjBzFV8MHMV3Xb7Qkbrfveu7LsqJtPv9en84Pj92WXH7A+1pWs3c94Dn3Dw3rsULD9hiYLZyX9P3z3x/17JbIiDk24NRrC86Z32F0sf+mhB2jOdmELeLPyHV6e1GY+nOUEvp2/eNiLtds65bzTzbz2THRIE/gsfGcusFXUpa87/fn/q0Uih7UXunz4xnorF61Ju81u3J873d+8axUmHdOXlX53cfmaGn226/8EVz03cer3qytN7bU2fsWx9SQO82tAjKlF3xNUZ3nBTaOm6RqazOMXTnEohvllm8pL8796dtaI8Iz3Gj/LZ3Jq+FpqoVwqQ9CwlUdny/VFKdUE7E+M/S/0UqXy7C4xbuG374fLnehNWrjIK6Ga2p5m9amZzzGy2mZ1sZl3NbKiZzfd/9yp2ZqVjeW1SVc5fhJ79BuXctaxQAX7AxwvbvO9zS/suk4nk033v+3enPvuZEdcM07PfIF7K4Vb/0ZWrE6bnkvdch+CNdW2FtjXyI69/P6N1Y2JDNcTS35y8jJnLt31OuYx39IdXpnLINYmPv1P6D+fiR8e2aXJ5duxixvjPdPD0FVuP3/5Z9oQqtkxr6PcA7zvnjgSOA2YD/YBhzrlewDD/XjoI3byRXvzNRKU4g4mNeZ/s3/NRAbvcZaLYw24Nn1OdfqGwDDL03NjFjMxhXKSwVyZW4Vzi6yjLajczZsGadtch3pkWNFW9MH5bR4KH09yrUGppGzbNbHfgVOCnAM65RqDRzM4FTvOLPQ2MBP5UjExK9kr1EOifPjkh42VHzavhlkGz+PW/HV7EHKWWbW2uUDeohP3lrRm8G3dbfcwdH8zlv75+MHvsvEPB95vIR3kGRggugp56+wh+8vWDWRk37s/dH87PqmthY0srvW9IX4Nvs//NzRx3c+phDCB4UtU5x+7fJu1xf+9AogpQpj1cZq+o23pxFbY9QKUcMqmhHwrUAE+a2WQze8zMdgX2dc6tAPB/90m0spn1NbMKM6uoqSlt7ePzrODD7hbApU+MZ96qeq58qXwPHSjXk5nC0o05/uCI9t0Ri6UQD1p5dNRCajc1cd/wSl6Z2P4hJ0OyDHDZDuL1cIYPBvnNC+1HDJ2XYjiFAaMWJp0XdmYZu7DGyySgdwFOBB5yzp0AbCSL5hXn3ADnXB/nXJ/u3bvnmE3JVkfqPztreV1ZfmAmL8nvQlq5fDSvhk8XrGkzOmJH9PH81TQ2tzJkZvlqpJD4cY7JvD9jRcLrCBWL1lEdgQHEMulLVgVUOedig4q8ShDQV5nZfs65FWa2H5BlY5l8Xlz06FgevOTEku83fmTJRAo1HEIhzVm5gYseHcvh++xW7qyk9MtnKrjgKz3KMnhZ+N82Lk0PlrArnks8tvrC1Rs5697RVFx3Rr5ZK6u0NXTn3EpgqZl92SedDswC3gYu82mXAW8VJYcSCYnGaCmH+POEjnwbfLh3R0eV69Of8tHqHFtSPD4xV6vrt7R7/kBYbF6ivvupOOdSbreQMu3l8lvgeTObBhwP/A3oD3zHzOYD3/HvRRLqKAE93qDpiS9OSmZml6E//aQltdxTpIGvjkpxQfbNKUEvl2y7cd45ZB5H3fB+0tEyCymj2/ecc1OAPglmnV7Y7EhUZfJUIJEoen1ScKF4/eamhMMPFJJu/ZeSyLanQ7Fc8HDq55KKpPKt27N7ctXPn6rYOl2Kh23r1n8piVKcbmbis9XJn0wkks7StR37TFMBXUSkBOJHDS0GBXQRkRIoQYuLArqISCmU4uY6BXQRkRJQDV1EJCJUQxcRiYhSjGakgC4iUgLq5SIiEhEZPO0vbwroIiIlkOjpSIWmgC4iUgLJHrZdSAroIiIRoYAuIhIRCugiIhGhgC4iEhEK6CIiEaGALiISEQroIiIRoYAuIhIRCugiIhGhgC4iEhEK6CIiEaGALiJSAlb8oVwU0EVEokIBXUQkIhTQRUQiQgFdRCQiFNBFRCJCAV1EJCIU0EVEIkIBXUQkIhTQRUQiQgFdRKQEnCv+PhTQRUQiQgFdRKQENJaLiIhkLOOAbmbbm9lkM3vXvz/EzMaZ2XwzG2hmOxYvmyIikk42NfQrgdmh97cBdznnegHrgMsLmTEREclORgHdzHoAZwOP+fcGfBt41S/yNHBeMTIoIiKZybSGfjfwR6DVv98bqHXONfv3VcABiVY0s75mVmFmFTU1NXllVkREkksb0M3sHKDaOTcxnJxg0YS9LJ1zA5xzfZxzfbp3755jNkVEJJ0uGSxzCvADMzsL2AnYnaDGvqeZdfG19B7A8uJlU0RE0klbQ3fOXeOc6+Gc6wlcCAx3zl0CjADO94tdBrxVtFyKiEha+fRD/xNwtZlVErSpP16YLImISC4yaXLZyjk3EhjppxcCJxU+SyIikgvdKSoiEhEK6CIiEaGALiJSAhqcS0REMqaALiISEQroIiIRoYAuIhIRCugiIhGhgC4iEhEK6CIiEaGALiJSAi7hAOOFpYAuIhIRCugiIhGhgC4iEhFf5B4vAAAIDElEQVQK6CIiJaCxXEREJGMK6CIiEaGALiISEQroIiIRoYAuIhIRCugiIhGhgC4iEhEK6CIiEaGALiISEQroIiIRoYAuIhIRCugiIiVgFH8wFwV0EZGIUEAXEYkIBXQRkYhQQBcRiQgFdBGRiFBAFxGJCAV0EZGIUEAXESkBhyv6PhTQRUQiQgFdRCQi0gZ0MzvQzEaY2Wwzm2lmV/r0rmY21Mzm+797FT+7IiKSTCY19Gbgf51zRwFfB35tZr2BfsAw51wvYJh/LyIiCXSIsVyccyucc5P89AZgNnAAcC7wtF/saeC8YmVSRETSy6oN3cx6AicA44B9nXMrIAj6wD5J1ulrZhVmVlFTU5NfbkVEJKmMA7qZ7Qa8BlzlnKvLdD3n3ADnXB/nXJ/u3bvnkkcREclARgHdzHYgCObPO+de98mrzGw/P38/oLo4WRQRkUxk0svFgMeB2c65f4ZmvQ1c5qcvA94qfPZERCRTXTJY5hTgJ8B0M5vi064F+gMvm9nlwBLgguJkUUREMpE2oDvnRkPS/janFzY7IiKSK90pKiISEQroIiIRoYAuIhIRCugiIhGhgC4iUgJW/KFcFNBFRKJCAV1EJCIU0EVEIkIBXUQkIhTQRUQiQgFdRCQiFNBFRErAueLvQwFdRCQiFNBFRCJCAV1EJCIU0EVEIkIBXUSkBDSWi4iIZEwBXUSkBNbUNxZ9HwroIiIlsH6zArqIiGRIAV1EJCIU0EVEIkIBXUQkIhTQRUQiQgFdRCQiFNBFRCJCAV1EJCIU0EVESqL4g7kooIuIRIQCuohIRCigi4hEhAK6iEhEKKCLiESEArqISER0ioD+wxMOKHcWRETy0nu/3Yu+j04R0O/68fEs6n82i/qfXe6siIjkZP89dyr6PvIK6Gb2fTOba2aVZtavUJkSEZHs5RzQzWx74AHgTKA3cJGZ9S5UxkREJDv51NBPAiqdcwudc43AS8C5hcmWiIhkK5+AfgCwNPS+yqe1YWZ9zazCzCpqamry2F3g4f86Me9tiIiUWpfti3/Jskse6yYaaca1S3BuADAAoE+fPu3mZ+v7x+yni6MiIgnk85NRBRwYet8DWJ5fdkREJFf5BPQJQC8zO8TMdgQuBN4uTLZERCRbOTe5OOeazew3wAfA9sATzrmZBcuZiIhkJZ82dJxz7wHvFSgvIiKSh05xp6iIiKSngC4iEhEK6CIiEaGALiISEeZc3vf6ZL4zsxpgcY6rdwNWFzA7nYHK/PmgMkdfvuU92DnXPd1CJQ3o+TCzCudcn3Lno5RU5s8HlTn6SlVeNbmIiESEArqISER0poA+oNwZKAOV+fNBZY6+kpS307Shi4hIap2phi4iIikooIuIRESnCOid+WHUZvaEmVWb2YxQWlczG2pm8/3fvXy6mdm9vpzTzOzE0DqX+eXnm9llofSvmNl0v869ZpbowSMlZWYHmtkIM5ttZjPN7EqfHtlym9lOZjbezKb6Mt/k0w8xs3E+/wP9UNOY2Rf8+0o/v2doW9f49Llm9r1Qeof7HpjZ9mY22cze9e8jXV4AM1vkj70pZlbh0zrGse2c69AvgqF5FwCHAjsCU4He5c5XFvk/FTgRmBFKux3o56f7Abf56bOAwQRPg/o6MM6ndwUW+r97+em9/LzxwMl+ncHAmR2gzPsBJ/rpLwLzCB4kHtly+3zs5qd3AMb5srwMXOjTHwb+20//D/Cwn74QGOine/tj/AvAIf7Y376jfg+Aq4EXgHf9+0iX1+d5EdAtLq1DHNtl/3Ay+PBOBj4Ivb8GuKbc+cqyDD1pG9DnAvv56f2AuX76EeCi+OWAi4BHQumP+LT9gDmh9DbLdZQX8Bbwnc9LuYFdgEnA1wjuDuzi07ceywTPETjZT3fxy1n88R1briN+DwieUjYM+Dbwrs9/ZMsbyssi2gf0DnFsd4Yml4weRt3J7OucWwHg/+7j05OVNVV6VYL0DsOfWp9AUGONdLl988MUoBoYSlDDrHXONftFwvncWjY/fz2wN9l/FuV0N/BHoNW/35tolzfGAUPMbKKZ9fVpHeLYzusBFyWS0cOoIyJZWbNN7xDMbDfgNeAq51xdiqbASJTbOdcCHG9mewJvAEclWsz/zbZsiSpfZSuzmZ0DVDvnJprZabHkBItGorxxTnHOLTezfYChZjYnxbIlPbY7Qw09ig+jXmVm+wH4v9U+PVlZU6X3SJBedma2A0Ewf94597pPjny5AZxztcBIgjbTPc0sVnEK53Nr2fz8PYC1ZP9ZlMspwA/MbBHwEkGzy91Et7xbOeeW+7/VBD/cJ9FRju1yt0dl0F7VheCCwSFsuzhydLnzlWUZetK2Df0O2l5Aud1Pn03bCyjjfXpX4DOCiyd7+emuft4Ev2zsAspZHaC8BjwD3B2XHtlyA92BPf30zsDHwDnAK7S9SPg/fvrXtL1I+LKfPpq2FwkXElwg7LDfA+A0tl0UjXR5gV2BL4amxwDf7yjHdtkPhgw/xLMIekosAP5c7vxkmfcXgRVAE8Gv7+UEbYfDgPn+b+wfacADvpzTgT6h7fwcqPSvn4XS+wAz/Dr34+/+LXOZv0lwmjgNmOJfZ0W53MCxwGRf5hnADT79UIJeC5U+2H3Bp+/k31f6+YeGtvVnX665hHo4dNTvAW0DeqTL68s31b9mxvLVUY5t3fovIhIRnaENXUREMqCALiISEQroIiIRoYAuIhIRCugiIhGhgC4iEhEK6CIiEfH/MOYt2cEBK4AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs)\n",
    "plt.title('Time Elapsed: {} Seconds'.format(toc - tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unknown error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-292-aec40b595e72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_copy_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_bits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0minput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cost'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: unknown error"
     ]
    }
   ],
   "source": [
    "batch = get_copy_batch(batch_size, 6, num_bits)\n",
    "input_batch, target_batch = batch[0].to(device), batch[1].to(device)\n",
    "result = evaluate(ntm, criterion, input_batch, target_batch)\n",
    "\n",
    "print(result['cost'].cpu().numpy())\n",
    "print(input_batch.cpu().numpy().squeeze())\n",
    "print(result['output_batch_bin'].cpu().numpy().squeeze())\n",
    "\n",
    "\n",
    "plt.imshow(np.hstack((input_batch.cpu().numpy().squeeze()[:,0:8].T, result['output_batch_bin'].cpu().numpy().squeeze().T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (30) : unknown error at C:\\w\\1\\s\\tmp_conda_3.7_044431\\conda\\conda-bld\\pytorch_1556686009173\\work\\torch/csrc/generic/serialization.cpp:23",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-304-5738a8054fc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'batch_num'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_state_dict'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'optimizer_state_dict'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'losses'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'costs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcosts\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ntm-{}task-{}.pt'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmake_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'copy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-304-5738a8054fc2>\u001b[0m in \u001b[0;36mmake_checkpoint\u001b[1;34m(model, optimizer, losses, costs, task_name, batch_num)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtask_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'batch_num'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_state_dict'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'optimizer_state_dict'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'losses'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'costs'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcosts\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ntm-{}task-{}.pt'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_num\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmake_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mntm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'copy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[1;34m(f, mode, body)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\PyTorch\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_save\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mserialized_storage_keys\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0mserialized_storages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_write_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_should_read_directly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: cuda runtime error (30) : unknown error at C:\\w\\1\\s\\tmp_conda_3.7_044431\\conda\\conda-bld\\pytorch_1556686009173\\work\\torch/csrc/generic/serialization.cpp:23"
     ]
    }
   ],
   "source": [
    "def make_checkpoint(model, optimizer, losses, costs, task_name, batch_num):\n",
    "    torch.save({'batch_num': batch_num, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict(), 'losses': losses, 'costs': costs }, 'ntm-{}task-{}.pt'.format(task_name, batch_num))\n",
    "    \n",
    "make_checkpoint(ntm, optimizer, losses, costs, 'copy', 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ntm-copytask-50000.pt'"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ntm-{}task-{}.pt'.format('copy', 50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
